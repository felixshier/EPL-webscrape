{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import requests\n",
    "import lxml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.premierleague.com\"\n",
    "page = requests.get(URL + \"/clubs\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubLinks = soup.findAll('a', {'class': 'indexItem'})\n",
    "clubs = []\n",
    "for link in clubLinks:\n",
    "    clubURL = URL + link['href']\n",
    "    clubURL = clubURL.replace(\"overview\", \"squad\")\n",
    "    clubs.append(clubURL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = []\n",
    "for club in clubs:\n",
    "    while True:\n",
    "        try:\n",
    "            clubPage = requests.get(club)\n",
    "            clubSoup = BeautifulSoup(clubPage.content, 'html.parser')\n",
    "            playerLinks = clubSoup.findAll('a', {'class': 'playerOverviewCard'})\n",
    "\n",
    "            for link in playerLinks:\n",
    "                playerURL = URL + link['href']\n",
    "                players.append(playerURL)\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validPositions = ['Goalkeeper', 'Midfielder', 'Defender', 'Forward']\n",
    "\n",
    "names = []\n",
    "clubs = []\n",
    "ages = []\n",
    "heights = []\n",
    "weights = []\n",
    "nations = []\n",
    "positions = []\n",
    "\n",
    "for player in players:\n",
    "    playerPage = requests.get(player)\n",
    "    playerSoup = BeautifulSoup(playerPage.content, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        playerName = playerSoup.findAll('div', {'class':'name'})\n",
    "        playerName = playerName[0].text.strip()\n",
    "        names.append(playerName)\n",
    "    except:\n",
    "        names.append(None)\n",
    "    try:\n",
    "        playerClub = playerSoup.findAll('td', {'class':'team'})\n",
    "        playerClub = playerClub[0].findAll('span', {'class':'short'})\n",
    "        playerClub = playerClub[0].text.strip()\n",
    "        clubs.append(playerClub)\n",
    "    except:\n",
    "        ages.append(None)\n",
    "    try:\n",
    "        playerAge = playerSoup.findAll('ul', {'class': 'pdcol2'})\n",
    "        playerAge = playerAge[0].findAll('span', {'class':'info--light'})\n",
    "        playerAge = playerAge[0].text.strip().replace('(', '').replace(')', '')\n",
    "        ages.append(playerAge)\n",
    "    except:\n",
    "        ages.append(None)\n",
    "    try:\n",
    "        playerPhysical = playerSoup.findAll('ul', {'class':'pdcol3'})\n",
    "        playerPhysical = playerPhysical[0].findAll('div', {'class': 'info'})\n",
    "        playerHeight = playerPhysical[0].text.strip()\n",
    "        heights.append(playerHeight)\n",
    "    except:\n",
    "        heights.append(None)\n",
    "    try:\n",
    "        playerPhysical = playerSoup.findAll('ul', {'class':'pdcol3'})\n",
    "        playerPhysical = playerPhysical[0].findAll('div', {'class': 'info'})\n",
    "        playerWeight = playerPhysical[1].text.strip()\n",
    "        weights.append(playerWeight)\n",
    "    except:\n",
    "        weights.append(None)\n",
    "    try:\n",
    "        playerNation = playerSoup.findAll('ul', {'class': 'pdcol1'})\n",
    "        playerNation = playerNation[0].findAll('div', {'class':'info'})\n",
    "        playerNation = playerNation[0].text.strip()\n",
    "        nations.append(playerNation)\n",
    "    except:\n",
    "        nations.append(None)\n",
    "    try:\n",
    "        temp = playerSoup.findAll('div', {'class':'info'})\n",
    "        tempPosition = temp[1].text.strip()\n",
    "        if tempPosition in validPositions:\n",
    "            playerPosition = tempPosition\n",
    "        else:\n",
    "            tempPosition = temp[0].text.strip()\n",
    "            playerPosition = tempPosition\n",
    "        positions.append(playerPosition)\n",
    "    except:\n",
    "        positions.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\Felix\\Documents\\pl_scrape\\pl_scrape.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
